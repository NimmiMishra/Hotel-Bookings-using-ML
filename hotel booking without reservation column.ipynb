{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08965d81-b2a8-465b-b89f-73de6a6002b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neema Mishra\\AppData\\Local\\Temp\\ipykernel_8044\\2094966805.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['children'].fillna(0, inplace=True)\n",
      "C:\\Users\\Neema Mishra\\AppData\\Local\\Temp\\ipykernel_8044\\2094966805.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['country'].fillna('Unknown', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "[[13570  1337]\n",
      " [ 2955  6016]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86     14907\n",
      "           1       0.82      0.67      0.74      8971\n",
      "\n",
      "    accuracy                           0.82     23878\n",
      "   macro avg       0.82      0.79      0.80     23878\n",
      "weighted avg       0.82      0.82      0.82     23878\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Random Forest Results:\n",
      "[[14082   825]\n",
      " [ 1732  7239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92     14907\n",
      "           1       0.90      0.81      0.85      8971\n",
      "\n",
      "    accuracy                           0.89     23878\n",
      "   macro avg       0.89      0.88      0.88     23878\n",
      "weighted avg       0.89      0.89      0.89     23878\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Decision Tree Results:\n",
      "[[13145  1762]\n",
      " [ 1645  7326]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89     14907\n",
      "           1       0.81      0.82      0.81      8971\n",
      "\n",
      "    accuracy                           0.86     23878\n",
      "   macro avg       0.85      0.85      0.85     23878\n",
      "weighted avg       0.86      0.86      0.86     23878\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier  # Ensure xgboost is installed\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('hotel_bookings.csv')  # Replace with your actual file path\n",
    "\n",
    "# Fill missing values\n",
    "df['children'].fillna(0, inplace=True)\n",
    "df['country'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Drop non-essential columns\n",
    "df.drop(columns=['agent', 'company', 'reservation_status', 'reservation_status_date'], inplace=True)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "categorical_cols = ['hotel', 'arrival_date_month', 'meal', 'country', \n",
    "                    'market_segment', 'distribution_channel', \n",
    "                    'customer_type', 'reserved_room_type', \n",
    "                    'assigned_room_type', 'deposit_type']\n",
    "\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['is_canceled'])  # Features\n",
    "y = df['is_canceled']  # Target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (optional)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"{model_name} Results:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ea6b3-e081-4bc4-8f4b-b2b5685d980a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
